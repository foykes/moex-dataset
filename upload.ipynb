{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsheets, pandas as pd, time, datetime, ftplib, sys, json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "\n",
    "current_path = sys.path[0]\n",
    "\n",
    "## Префикс секретов\n",
    "secrets_prefix = current_path.rsplit(\"/\", 1)[0] + \"/secrets/\"\n",
    "\n",
    "## Гугл док для сохранения данных\n",
    "gdoc_to_write = \"https://docs.google.com/spreadsheets/d/1HXXoxcDVqIrWN6QEg5ij88AxcNAKT-G-xm2UTUfQe1Q/edit?usp=sharing\"\n",
    "\n",
    "\n",
    "datasets_path = current_path + \"/datasets/\"\n",
    "\n",
    "\n",
    "## Начальное время\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdoc_upload(current_path, gdoc_to_write):\n",
    "    print('Начал загрузку данных на Google Диск и FTP.\\nВремя старта: {}'.format(datetime.datetime.now()))\n",
    "\n",
    "    ## Префикс секретов\n",
    "    secrets_prefix = current_path.rsplit(\"/\", 1)[0] + \"/secrets/\"\n",
    "\n",
    "    service_account_json = secrets_prefix + '/python-304621-1e403209f05f.json'\n",
    "    gc = pygsheets.authorize(service_file=service_account_json)\n",
    "\n",
    "    ### Подготовка данных для гугл дока\n",
    "    df = pd.read_csv(datasets_path + \"10years_data_1d_interval.csv\")\n",
    "    # df = df.round(decimals = 2) #округление до 2 цифр\n",
    "    # df.sort_values(by=0, ascending=True, inplace=True) #сортировка\n",
    "\n",
    "    ### Убирание ненужных колонок, чтобы не упираться в лимит в 10кк ячеек гугл доков\n",
    "    columns = df.columns\n",
    "    white_list_columns = ['open', 'close', 'high', 'low', 'value', 'volume', 'begin', 'end',\n",
    "        'ticker', 'RSI14']\n",
    "    columns_to_remove = [i for i in columns if i not in white_list_columns]\n",
    "    columns_to_remove\n",
    "    df.drop(columns_to_remove, axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    ### Загрузка данных на гугл док\n",
    "\n",
    "    try:\n",
    "        google_doc = gc.open_by_url(gdoc_to_write)\n",
    "\n",
    "        #opening needed sheet\n",
    "        needed_sheet = google_doc[0]\n",
    "\n",
    "        #clearing all data\n",
    "        needed_sheet.clear()\n",
    "\n",
    "        #writing data\n",
    "        needed_sheet.set_dataframe(df, 'A1', copy_index=False, copy_head=True, fit=False, escape_formulae=False, nan='NaN')\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка: {e}\")\n",
    "\n",
    "\n",
    "    # конечное время\n",
    "    end_time = time.time()\n",
    "\n",
    "    # разница между конечным и начальным временем\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    mins, secs = divmod(elapsed_time, 60)\n",
    "    hours, mins = divmod(mins, 60)\n",
    "\n",
    "    print('Обновление данных на Google Диске закончено.\\nЗаняло времени: {} часов, {} минут, {} секунд. Суммарно в секундах: {}'. format(round(hours), round(mins), round(secs), round(elapsed_time, 3), 'сек'))\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ftp_upload(current_path):\n",
    "\n",
    "    secrets_prefix = current_path.rsplit(\"/\", 1)[0] + \"/secrets/\"\n",
    "\n",
    "    ## Получение секрета подключения к FTP\n",
    "    ftp_secrets_path = open(secrets_prefix + \"moex.foykes.com.json\")\n",
    "    ftp_data = json.load(ftp_secrets_path)\n",
    "    ftp_secrets_path.close()\n",
    "\n",
    "    ## Подключение к FTP\n",
    "    ftp_server = ftplib.FTP(ftp_data['domain'], ftp_data['username'], ftp_data['password'])\n",
    "    ftp_server.encoding = \"utf-8\"\n",
    "\n",
    "    ## Загрузка основных датасетов\n",
    "    datasets_list = [f for f in listdir(datasets_path) if isfile(join(datasets_path, f))]\n",
    "    datasets_list = list(set(datasets_list)) #дедуп\n",
    "    \n",
    "    try:\n",
    "        for i in range(0,len(datasets_list)):\n",
    "            file_path = datasets_path + \"/\" + datasets_list[i]\n",
    "            where_upload = \"STOR {}\".format(datasets_list[i])\n",
    "            \n",
    "            with open(file_path, \"rb\") as file:\n",
    "                ftp_server.storbinary(where_upload, file)\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка: {e}\")\n",
    "\n",
    "\n",
    "    ## Загрузка дивидендов\n",
    "    datasets_path_divs = datasets_path + \"/dividends\"\n",
    "    datasets_list = [f for f in listdir(datasets_path_divs) if isfile(join(datasets_path_divs, f))]\n",
    "    datasets_list = list(set(datasets_list)) #дедуп\n",
    "\n",
    "    try:\n",
    "        for i in range(0,len(datasets_list)):\n",
    "            file_path = datasets_path_divs + \"/\" + datasets_list[i]\n",
    "            where_upload = \"STOR dividends/{}\".format(datasets_list[i])\n",
    "            \n",
    "            with open(file_path, \"rb\") as file:\n",
    "                ftp_server.storbinary(where_upload, file)\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка: {e}\")\n",
    "\n",
    "        \n",
    "    ## Загрузка списка тикеров\n",
    "    datasets_path_divs = datasets_path + \"/ticker_lists\"\n",
    "    datasets_list = [f for f in listdir(datasets_path_divs) if isfile(join(datasets_path_divs, f))]\n",
    "    datasets_list = list(set(datasets_list)) #дедуп\n",
    "\n",
    "    try:\n",
    "        for i in range(0,len(datasets_list)):\n",
    "            file_path = datasets_path_divs + \"/\" + datasets_list[i]\n",
    "            where_upload = \"STOR ticker_lists/{}\".format(datasets_list[i])\n",
    "            \n",
    "            with open(file_path, \"rb\") as file:\n",
    "                ftp_server.storbinary(where_upload, file)\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка: {e}\")\n",
    "\n",
    "    ## Закрытие подключения к FTP   \n",
    "    ftp_server.quit()\n",
    "\n",
    "\n",
    "    # конечное время\n",
    "    end_time = time.time()\n",
    "\n",
    "    # разница между конечным и начальным временем\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    mins, secs = divmod(elapsed_time, 60)\n",
    "    hours, mins = divmod(mins, 60)\n",
    "\n",
    "    print('Загрузка данных на FTP закончена.\\nЗаняло времени: {} часов, {} минут, {} секунд. Суммарно в секундах: {}'. format(round(hours), round(mins), round(secs), round(elapsed_time, 3), 'сек'))\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(current_path,gdoc_to_write):\n",
    "    # end_time = gdoc_upload(current_path, gdoc_to_write)\n",
    "    # end_time_ftp = ftp_upload(current_path)\n",
    "\n",
    "    p1 = Process(target=gdoc_upload, args=(current_path, gdoc_to_write))\n",
    "    p1.start()\n",
    "    p2 = Process(target=ftp_upload, args=(current_path,))\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "\n",
    "    # конечное время\n",
    "    end_time_ftp = time.time()\n",
    "\n",
    "    # разница между конечным и начальным временем\n",
    "    elapsed_time = end_time_ftp - start_time\n",
    "\n",
    "    mins, secs = divmod(elapsed_time, 60)\n",
    "    hours, mins = divmod(mins, 60)\n",
    "\n",
    "    print('Скрипт загрузки данных закончил работу.\\nЗаняло времени: {} часов, {} минут, {} секунд. Суммарно в секундах: {}'. format(round(hours), round(mins), round(secs), round(elapsed_time, 3), 'сек'))\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    main(current_path,gdoc_to_write)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
